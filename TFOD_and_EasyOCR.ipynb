{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFOD_and_EasyOCR.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNtbmyhn1uwIBCN1sdr0kOk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nnamaka/OCR_with_TFOD_and_EasyOCR/blob/main/TFOD_and_EasyOCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Perform OCR on a selected ROI(Region Of Interest) custom document \n",
        "To achieve this, the task is divided into two major parts. Text Detection and Text recognition. For the Text Detection, We will use a different model today,  CenterNet_MobileNetV2_FPN_512x512 from the TFOD(Tensorflow object detection) model zoo, perform transfer learning on it and train the model to detect certain ROIs on the custom document. Now for the Text Recognition, I will use an OCR model EasyOCR. There are other great OCR models to use eg Tesseract, PaddleOCR etc. \n"
      ],
      "metadata": {
        "id": "SKmaWaMGNCWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Part 1 - ROI detection(Text detection)**"
      ],
      "metadata": {
        "id": "6bzXo0dQLLKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creat our folder structure"
      ],
      "metadata": {
        "id": "6V8QI6MNSg-k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJrWJu1KMxjg"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "3dFmYP-NrY8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declaring and Assigning variable names."
      ],
      "metadata": {
        "id": "5kNU04yEyato"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ],
      "metadata": {
        "id": "ZFqnFCjnSgiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store paths in `path` dictionary."
      ],
      "metadata": {
        "id": "YlUBNGXSyqyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ],
      "metadata": {
        "id": "HlxbQbKNyRrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ],
      "metadata": {
        "id": "QmLAMMWYyV40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create directories."
      ],
      "metadata": {
        "id": "sGHRyPN9zBH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ],
      "metadata": {
        "id": "COovrTSuzEHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Download model and install TFOD(Tensorflow object detection)"
      ],
      "metadata": {
        "id": "p7OyDkdnzeCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install model."
      ],
      "metadata": {
        "id": "ZGlroI4Xz4MQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ],
      "metadata": {
        "id": "7p-3DWvCz6X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install TFOD.\n",
        "\n",
        "`posix` is for linux based system eg ubuntu, Mac OS.\n",
        "> \n",
        "`nt` is windows."
      ],
      "metadata": {
        "id": "Ab7TAuSBz9jX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e ."
      ],
      "metadata": {
        "id": "E-iI_X_Q0ATF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install extra dependencies."
      ],
      "metadata": {
        "id": "P5KKRYOJ0g4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade opencv-contrib-python\n",
        "\n",
        "!pip uninstall opencv-python==4.1.2.30 -y\n",
        "!pip install opencv-python==4.5.5.64\n",
        "\n",
        "!pip uninstall opencv-python-headless==4.1.2.30 -y\n",
        "!pip install opencv-python-headless==4.5.5.64"
      ],
      "metadata": {
        "id": "6P_AdQWG1eyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dill==0.3.4 cloudpickle==1.2.0 requests==2.23.0 folium==0.2.1 imgaug==0.2.5"
      ],
      "metadata": {
        "id": "U8nzcvts0l1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Verification Script."
      ],
      "metadata": {
        "id": "n_hljrDB1y_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ],
      "metadata": {
        "id": "CXdUNHJE15nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install/Upgrade Tensorflow if necessary."
      ],
      "metadata": {
        "id": "u57uLnjE16WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow --upgrade\n",
        "#!pip install tensorflow --upgrade tensorflow==1.15\n",
        "# !pip install tensorflow --upgrade tensorflow==2.8.0\n",
        "# !pip install tensorflow --upgrade tensorflow==2.5"
      ],
      "metadata": {
        "id": "BX2458an2LE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the Object detection model for sanity check."
      ],
      "metadata": {
        "id": "POlpQfm22OnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import object_detection"
      ],
      "metadata": {
        "id": "E81z2JG42r5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Pretrained Model."
      ],
      "metadata": {
        "id": "vTgWdsky2u7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the name of the model is different when you download it\n",
        "# name_ext = \"centernet_mobilenetv2fpn_512x512_coco17_od\"\n",
        "\n",
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    # !mv {name_ext+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "    # !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {name_ext+'.tar.gz'}\n",
        "\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    # !mv {name_ext+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "    # !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {name_ext+'.tar.gz'}"
      ],
      "metadata": {
        "id": "-XjEhxKd24Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create Label Map."
      ],
      "metadata": {
        "id": "fG7gnXDJ26rZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you modify the values of the list `labels` according to the labels you want and have annotated your Dataset to detect."
      ],
      "metadata": {
        "id": "Fw7gSMXr3IVs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this particular OCR task, I am targeting two certain ROI's(Region of interest) on a document.\n",
        "\n",
        "> Therefore, I have them labeled as `chapter` and `title`.\n",
        "\n",
        "\n",
        "> please note that these labels are case sensitive. You should be consistent with Whatever label name you used in annotating your dataset.\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "iMRzMIsP48Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example:\n",
        "# labels = [{'name':'ThumbsUp', 'id':1}, {'name':'ThumbsDown', 'id':2}, {'name':'ThankYou', 'id':3}, {'name':'LiveLong', 'id':4}]\n",
        "\n",
        "labels = [{'name':'chapter', 'id':1}, {'name':'title', 'id':2}]\n",
        "\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ],
      "metadata": {
        "id": "1KdfQ4di3DnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create TF Records"
      ],
      "metadata": {
        "id": "1cEiQljl6gPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I stored my dataset in google drive."
      ],
      "metadata": {
        "id": "Yc8EfBTK6k3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BIEqrkaR6x3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Note: My dataset has already been annotated and splitted into `train`-`test` dataset. After that I compressed the dataset, named it `archive.tar.gz` and sent it to my google drive.\n",
        "\n",
        "The code to compress your images is:\n",
        "\n",
        "> `tar -czf {ARCHIVE_PATH} {TRAIN_PATH} {TEST_PATH}`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oO2wpa_Z7vgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/MyDrive/TFOD images/archive.tar.gz' {paths['IMAGE_PATH']}"
      ],
      "metadata": {
        "id": "x6eeoAkO_jMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uncompress the file and move them to the images path"
      ],
      "metadata": {
        "id": "Fs23-EqsBB6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}\n",
        "  !mv '/content/test' '/content/train' {paths['IMAGE_PATH']}"
      ],
      "metadata": {
        "id": "gWa4gLvzBVE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  !mv '/content/newSet/test' '/content/newSet/train' {paths['IMAGE_PATH']}"
      ],
      "metadata": {
        "id": "0zo90PGaI8py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the TR Record Script and create the TF Record"
      ],
      "metadata": {
        "id": "sH03pT8HBsjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ],
      "metadata": {
        "id": "-vt_y--ECMQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}\n"
      ],
      "metadata": {
        "id": "gtDi574TCabv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Copy Model config file to training folder"
      ],
      "metadata": {
        "id": "n2ZQ58k44ULR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the folder from the decompressed model changed\n",
        "# folder_name = \"centernet_mobilenetv2_fpn_od\"\n",
        "if os.name =='posix':\n",
        "    \n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "    # !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], folder_name, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "    # !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], folder_name, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ],
      "metadata": {
        "id": "VBqsY3LK4c3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "update config file for transfer learning"
      ],
      "metadata": {
        "id": "TWbWt2yg4jye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "metadata": {
        "id": "hQoV6W0x4hm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ],
      "metadata": {
        "id": "nk0QrFHV5B9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "id": "6ypdc3Ia5C7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ],
      "metadata": {
        "id": "B5oGdYzi5DyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ],
      "metadata": {
        "id": "OlKMWcly5EDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)"
      ],
      "metadata": {
        "id": "ehDAtmSH5Psw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train the model"
      ],
      "metadata": {
        "id": "PfSE4D5r5Rr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ],
      "metadata": {
        "id": "oGA0cmej5bGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])\n"
      ],
      "metadata": {
        "id": "oN5zADeM5Q20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(command)"
      ],
      "metadata": {
        "id": "5QaF7L255uAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!{command}"
      ],
      "metadata": {
        "id": "srz9eOMl5uUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluate the Model"
      ],
      "metadata": {
        "id": "nvbs2usE50v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\n"
      ],
      "metadata": {
        "id": "OZZ2KM-c5uec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(command)\n"
      ],
      "metadata": {
        "id": "A8pDT4fI58xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!{command}\n"
      ],
      "metadata": {
        "id": "0g0Vd8sL588c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load Trained Model from Checkpoint"
      ],
      "metadata": {
        "id": "cVWhBE476Cqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ],
      "metadata": {
        "id": "w_JZwDiS59HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu_device = tf.config.list_physical_devices('GPU')\n",
        "# mem_alloc = [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)]\n",
        "# tf.config.experimental.set_virtual_device_configuration(\n",
        "#  gpu_device[0],mem_alloc)"
      ],
      "metadata": {
        "id": "JySkN4haRKu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: for loading the correct and the latest checkpoint, go into Tensorflow/workspace/models/my_ssd_mobnet and see the number of the last checkpoint, then make the changes accordingly in second argument of ckpt.restore() function"
      ],
      "metadata": {
        "id": "Ua2Eu_mY6SKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ],
      "metadata": {
        "id": "HqZ9oVkG6J6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Detect from an Image"
      ],
      "metadata": {
        "id": "etwuNNLL6ZXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "8XDJyCoj6KGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ],
      "metadata": {
        "id": "MjLfLWNC6KRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get Image"
      ],
      "metadata": {
        "id": "E_KNWug36n4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'IMG_20220514_171412_601.jpg'\n",
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', name)"
      ],
      "metadata": {
        "id": "9AA46wTT6Kdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nV4wmU2z59R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Part2 - Applying OCR(Text Recognition)**"
      ],
      "metadata": {
        "id": "QR8MozVODuU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In part 1, we detected the Region of interest on our document ( Text detection ). Now we will use the extracted region of interest and run it through an OCR model in other to interprete the text in it. This is called Text Recognition."
      ],
      "metadata": {
        "id": "3M0AbCHtKRY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[EasyOCR](https://github.com/JaidedAI/EasyOCR) is the OCR model we will use in this project. It runs on GPU, so we need to share it some GPU memory.\n",
        "\n",
        "If you think you don't have enough GPU memory, then follow along the instruction in the cell below."
      ],
      "metadata": {
        "id": "asSnwTzNKSLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Follow this cell only if you don't have enough GPU memory***\n",
        "\n",
        "Just before we run our text detection model, we will need to partition our GPU memory so we can run text recognition with EasyOCR right after. \n",
        "\n",
        "To do this we inserted and commented out a piece of code right after where we made imports at the***load trained model from checkpoint*** section of our notebook.Uncomment the code to use it.\n",
        "\n",
        "see the code below\n",
        "\n",
        "\n",
        ">\n",
        ".\n",
        "```\n",
        "gpu_device = tf.config.list_physical_devices('GPU')\n",
        "mem_alloc = [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)]\n",
        "tf.config.experimental.set_virtual_device_configuration(\n",
        " gpu_device[0],mem_alloc)\n",
        "```\n"
      ],
      "metadata": {
        "id": "xX836NQGN7Yr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets see what our `detections` dictionary contains"
      ],
      "metadata": {
        "id": "O76E_5d5U8Kq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detections.keys()"
      ],
      "metadata": {
        "id": "5MeB5dr-8piu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "install EasyOCR"
      ],
      "metadata": {
        "id": "tPF-89DYVHMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "id": "mxGOukhW8ps7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import easyocr\n",
        "\n",
        "thresh = 0.7"
      ],
      "metadata": {
        "id": "4_q5Z7XfVRXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that our images with its detections is saved in `image_with_detections` variable"
      ],
      "metadata": {
        "id": "BqY4DPFhXOtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = list(filter(lambda x: x >thresh, detections['detection_scores']))\n",
        "boxes = detections['detection_boxes'][:len(scores)]\n",
        "classes = detections['detection_classes'][:len(scores)]"
      ],
      "metadata": {
        "id": "q7fEWkcKW8qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "renormalize our detection boxes with respect to the image size."
      ],
      "metadata": {
        "id": "X1fXXErvZqTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "height, width = image_np_with_detections.shape[0], image_np_with_detections.shape[1]"
      ],
      "metadata": {
        "id": "AMY8wOqmZHDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "height"
      ],
      "metadata": {
        "id": "Jm7jfEBHZMrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width"
      ],
      "metadata": {
        "id": "Q9nCU4tmbfi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets go through our detections and apply OCR to those regions"
      ],
      "metadata": {
        "id": "eywh8X-Gcbnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, box in enumerate(boxes):\n",
        "  print(box)"
      ],
      "metadata": {
        "id": "C-uq_wT8b2ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9JBYNf4bbhgU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}